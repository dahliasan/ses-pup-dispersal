[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data Access",
    "section": "",
    "text": "The following datasets are available through Dryad: [DOI: pending]\n\n\n\nJuvenile Seal Tracks (tracks_processed_12h.csv)\n\n49 individual seals\n14,162 locations\n12-hour intervals\nARGOS locations processed using state-space models\nVariables: id, date, lon, lat, flag\n\nAdult Female Tracks (adult_female_locs.csv)\n\n67 individual females\n101,905 locations\n6-hour intervals\nARGOS and GLS locations\nVariables: id, date, lon, lat, type, month, season\n\n\n\n\n\n\nDeep Particle Traces (particle-trace-186.13m.csv)\n\n48 particle trajectories\n5,603 locations\nDepth: 186.13m\nVariables: id, date, lon, lat\n\nSurface Particle Traces (currently_particleTrace.csv)\n\n48 particle trajectories\n11,164 locations\nDepth: surface\nVariables: id, date, lon, lat\n\n\n\n\n\n\nDataset Summary (dataset_metadata_summary.csv)\n\nSummary statistics for each dataset\nTemporal coverage\nNumber of records\nDataset descriptions\n\nSeal Identification Data (seal_id.csv)\n\n98 unique seal identifiers\nVariables: ref, ptt, brand, tag1, tag2, SEAL_ID\nIncludes data from multiple years (1995-2000)\nLinks PTT numbers to unique SEAL_ID for cross-referencing\n\n\n\n\n\n\n\nAll seal tracks processed using foieGras R package\nParticle traces generated using currently R package\nQuality control flags indicate suspicious tracks\nAll coordinates in decimal degrees (WGS84)\nSeal IDs standardized across datasets for consistent referencing"
  },
  {
    "objectID": "data.html#complete-datasets",
    "href": "data.html#complete-datasets",
    "title": "Data Access",
    "section": "",
    "text": "The following datasets are available through Dryad: [DOI: pending]\n\n\n\nJuvenile Seal Tracks (tracks_processed_12h.csv)\n\n49 individual seals\n14,162 locations\n12-hour intervals\nARGOS locations processed using state-space models\nVariables: id, date, lon, lat, flag\n\nAdult Female Tracks (adult_female_locs.csv)\n\n67 individual females\n101,905 locations\n6-hour intervals\nARGOS and GLS locations\nVariables: id, date, lon, lat, type, month, season\n\n\n\n\n\n\nDeep Particle Traces (particle-trace-186.13m.csv)\n\n48 particle trajectories\n5,603 locations\nDepth: 186.13m\nVariables: id, date, lon, lat\n\nSurface Particle Traces (currently_particleTrace.csv)\n\n48 particle trajectories\n11,164 locations\nDepth: surface\nVariables: id, date, lon, lat\n\n\n\n\n\n\nDataset Summary (dataset_metadata_summary.csv)\n\nSummary statistics for each dataset\nTemporal coverage\nNumber of records\nDataset descriptions\n\nSeal Identification Data (seal_id.csv)\n\n98 unique seal identifiers\nVariables: ref, ptt, brand, tag1, tag2, SEAL_ID\nIncludes data from multiple years (1995-2000)\nLinks PTT numbers to unique SEAL_ID for cross-referencing"
  },
  {
    "objectID": "data.html#data-processing",
    "href": "data.html#data-processing",
    "title": "Data Access",
    "section": "",
    "text": "All seal tracks processed using foieGras R package\nParticle traces generated using currently R package\nQuality control flags indicate suspicious tracks\nAll coordinates in decimal degrees (WGS84)\nSeal IDs standardized across datasets for consistent referencing"
  },
  {
    "objectID": "code/export-data.html",
    "href": "code/export-data.html",
    "title": "Export data for publication",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(here)\n\n\nhere() starts at /Users/dahlia/Library/CloudStorage/OneDrive-UniversityofTasmania/Research/Weaner Dispersal Project/Data Analysis/ses-pup-dispersal\n\n\nCode\nlibrary(sf)\n\n\nWarning: package 'sf' was built under R version 4.4.1\n\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\nCode\n# Load data\nfiles &lt;- list(\n    seal_data_path = here(\"output\", \"tracks_processed_12h.rds\"),\n    female_data_path = here(\"data\", \"adult_female_locs.rds\"),\n    particle_data_path = here(\"output\", \"particle-trace-186.13m.rds\"),\n    surface_particle_data_path = here(\"output\", \"currently_particleTrace.rds\")\n)\n\n\n\n\nCode\nload(here(\"output\", \"seal_id.rdata\"))\nls()\n\n\n[1] \"files\"           \"has_annotations\" \"sealID_all\"     \n\n\nCode\nsealID_all %&gt;% print(n = 100)\n\n\n# A tibble: 98 × 6\n   ref               ptt brand tag1  tag2  SEAL_ID\n   &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 mq1-2849-95      2849 J373  9788  &lt;NA&gt;     8108\n 2 mq1-5811-95      5811 J032  8048  8049     7254\n 3 mq1-5814-95      5814 J239  8392  8393     7375\n 4 mq1-17215-95    17215 J622  9500  9501     7932\n 5 mq1-20916-95    20916 J723  8728  8729     7582\n 6 mq1-20918-95    20918 J503  8203  &lt;NA&gt;     7308\n 7 mq1-22483-95    22483 J806  9538  9539     7947\n 8 mq1-22484-95    22484 J557  8874  8875     7627\n 9 mq1-22486-95    22486 J781  8870  8871     7625\n10 mq1-22490-95    22490 J429  8927  8928     7664\n11 mq1-22500-95    22500 J803  8340  8341     7392\n12 mq1-22501-95    22501 J012  8258  8259     7357\n13 mq1-26625-95    26625 J766  8114  8115     7279\n14 mq1-26628-95    26628 J483  9230  9231     7855\n15 mq1-26629-95    26629 J708  8598  8599     7497\n16 mq1-26633-95    26633 J591  9017  9018     7710\n17 mq1-26635-95    26635 J375  8742  8743     7542\n18 mq1-17217-95    17217 J226  9346  9347     7915\n19 mq1-17219-95    17219 J615  8040  8041     7244\n20 mq1-22499-95    22499 J415  9711  9712     8055\n21 mq1-26627-95    26627 J091  8607  &lt;NA&gt;     7501\n22 mq1-2846-95      2846 J100  9027  9028     7698\n23 mq1-5810-95      5810 J219  8310  8311     7353\n24 mq1-5815-95      5815 J332  9069  9070     7761\n25 mq1-5816-95      5816 J604  8957  8958     7726\n26 mq1-17213-95    17213 J627  9173  9174     7780\n27 mq1-17216-95    17216 J336  9240  9241     7823\n28 mq1-17221-95    17221 J387  8722  8723     7579\n29 mq1-20915-95    20915 J026  8282  8283     7369\n30 mq1-20917-95    20917 J239  8392  8393     7375\n31 mq1-22482-95    22482 J622  9500  9501     7932\n32 mq1-22485-95    22485 J575  8696  8697     7570\n33 mq1-22487-95    22487 J243  8292  8293     7326\n34 mq1-22488-95    22488 J693  8896  8897     7671\n35 mq1-22497-95    22497 J726  8618  8619     7522\n36 mq1-26624-95    26624 J362  8935  8936     7668\n37 mq1-26626-95    26626 J356  8453  8454     7445\n38 mq1-26631-95    26631 J708  8598  8599     7497\n39 mq1-26632-95    26632 J803  8340  8341     7392\n40 mq2-20916-96    20916 K887  &lt;NA&gt;  &lt;NA&gt;     9774\n41 mq2-20917-96    20917 K354  966   967      9748\n42 mq2-22500-96    22500 K339  669   670      9574\n43 mq2-26623-96    26623 K397  795   796      9637\n44 mq2-28482-96    28482 K223  725   726      9602\n45 mq2-28479-96    28479 K875  2359  2360    10450\n46 mq3-2846-99      2846 T232  &lt;NA&gt;  &lt;NA&gt;    25783\n47 mq3-2849-99      2849 T825  &lt;NA&gt;  &lt;NA&gt;    26468\n48 mq3-5812-99      5812 T887  &lt;NA&gt;  &lt;NA&gt;    26605\n49 mq3-17217-99    17217 T088  &lt;NA&gt;  &lt;NA&gt;    26415\n50 mq3-20918-99    20918 T875  &lt;NA&gt;  &lt;NA&gt;    26290\n51 mq3-22484-99    22484 T806  &lt;NA&gt;  &lt;NA&gt;    25910\n52 mq3-22488-99    22488 T899  &lt;NA&gt;  &lt;NA&gt;    25966\n53 mq3-22498-99    22498 T857  &lt;NA&gt;  &lt;NA&gt;    25859\n54 mq3-26627-99    26627 T867  &lt;NA&gt;  &lt;NA&gt;    26244\n55 mq3-26629-99    26629 T773  &lt;NA&gt;  &lt;NA&gt;    26535\n56 mq3-28494-99    28494 T807  &lt;NA&gt;  &lt;NA&gt;    26342\n57 mq3-28496-99    28496 T823  &lt;NA&gt;  &lt;NA&gt;    26139\n58 mq3-28497-99    28497 T839  &lt;NA&gt;  &lt;NA&gt;    25949\n59 mq3-28500-99    28500 T772  &lt;NA&gt;  &lt;NA&gt;    26560\n60 mq3-28504-99    28504 T719  &lt;NA&gt;  &lt;NA&gt;    25673\n61 mq3-2849a-99     2849 T825  &lt;NA&gt;  &lt;NA&gt;    26468\n62 mq3-5812a-99     5812 T887  &lt;NA&gt;  &lt;NA&gt;    26605\n63 mq3-17217a-99   17217 T088  &lt;NA&gt;  &lt;NA&gt;    26415\n64 mq3-28496a-99   28496 T823  &lt;NA&gt;  &lt;NA&gt;    26139\n65 mq3-28504a-99   28504 T719  &lt;NA&gt;  &lt;NA&gt;    25673\n66 mq2-22483-96    22483 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n67 mq2-22490-96    22490 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n68 mq2-26624-96    26624 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n69 mq2-22486-96    22486 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n70 mq2-22488-96    22488 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n71 mq2-22497-96    22497 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n72 mq2-22499-96    22499 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n73 mq2-28483-96    28483 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n74 mq3-2841-99      2841 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n75 mq3-2845-99      2845 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n76 mq3-26635-99    26635 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n77 mq3-2442-99      2442 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n78 mq3-2841a-99     2841 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n79 mq3-2841b-99     2841 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n80 mq3-2841c-99     2841 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n81 mq3-2845a-99     2845 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n82 mq3-2845b-99     2845 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n83 mq3-2845c-99     2845 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n84 mq3-22500-99    22500 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n85 mq3-26635a-99   26635 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n86 mq3-26635b-99   26635 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n87 mq3-26635c-99   26635 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n88 mq3-28502-99    28502 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n89 mq3-28505a-99   28505 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n90 mq3-28505-99    28505 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;       NA\n91 mq4-Alice-00     1547 &lt;NA&gt;  W3762 W3763   28562\n92 mq4-Billie-00   17214 &lt;NA&gt;  W3998 W3999   28680\n93 mq4-Cleo-00     17216 &lt;NA&gt;  W2706 W2707   28029\n94 mq4-FirstOne-00 17217 &lt;NA&gt;  W3000 W3001   28181\n95 mq4-Doris-00    20916 &lt;NA&gt;  W4197 W4198   28775\n96 mq4-20918-00    20918 &lt;NA&gt;  W4191 W4231   28783\n97 mq4-Ella-00     22489 &lt;NA&gt;  W3325 W3326   28345\n98 mq4-Flora-00    26624 &lt;NA&gt;  W3843 W3844   28603\n\n\nCode\nwrite_csv(sealID_all, here(\"output\", \"seal_id.csv\"))\n\n\n\n\nCode\nget_dataset_info &lt;- function(file_path, dataset_name) {\n    data &lt;- read_rds(file_path) %&gt;%\n        ungroup() %&gt;%\n        st_drop_geometry()\n\n    # Time coverage using reframe instead of summarise\n    time_range &lt;- data %&gt;%\n        reframe(\n            start_date = min(date, na.rm = TRUE),\n            end_date = max(date, na.rm = TRUE),\n            n_records = n()\n        )\n\n    # Spatial coverage using reframe\n    spatial_range &lt;- data %&gt;%\n        reframe(\n            lon_min = min(lon, na.rm = TRUE),\n            lon_max = max(lon, na.rm = TRUE),\n            lat_min = min(lat, na.rm = TRUE),\n            lat_max = max(lat, na.rm = TRUE)\n        )\n\n    # Variable names and classes (removing duplicates)\n    var_info &lt;- data %&gt;%\n        summarise(across(everything(), ~ class(.x)[1])) %&gt;% # Take only first class\n        pivot_longer(everything(),\n            names_to = \"variable\",\n            values_to = \"class\"\n        ) %&gt;%\n        distinct() # Remove any remaining duplicates\n\n    # Number of unique IDs\n    n_ids &lt;- data %&gt;%\n        pull(id) %&gt;%\n        n_distinct()\n\n    # Print summary\n    cat(\"\\n=== Dataset:\", dataset_name, \"===\\n\")\n    cat(\"\\nTime Coverage:\\n\")\n    print(time_range)\n\n    cat(\"\\nSpatial Coverage:\\n\")\n    print(spatial_range)\n\n    cat(\"\\nNumber of unique IDs:\", n_ids, \"\\n\")\n\n    cat(\"\\nVariables and their classes:\\n\")\n    print(var_info)\n\n    cat(\"\\nSample size:\", nrow(data), \"records\\n\")\n\n    # Return invisibly for potential further use\n    invisible(list(\n        time_range = time_range,\n        spatial_range = spatial_range,\n        var_info = var_info,\n        n_ids = n_ids,\n        data = data # Include the data for CSV export\n    ))\n}\n\n\n\n\nCode\n# Get metadata for each dataset\nseal_info &lt;- get_dataset_info(files$seal_data_path, \"seal_data\")\n\n\n\n=== Dataset: seal_data ===\n\nTime Coverage:\n# A tibble: 1 × 3\n  start_date          end_date            n_records\n  &lt;dttm&gt;              &lt;dttm&gt;                  &lt;int&gt;\n1 1995-11-27 02:00:00 2002-01-05 18:00:00     14162\n\nSpatial Coverage:\n# A tibble: 1 × 4\n  lon_min lon_max lat_min lat_max\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1   -180.    180.   -67.0   -43.8\n\nNumber of unique IDs: 49 \n\nVariables and their classes:\n# A tibble: 12 × 2\n   variable           class    \n   &lt;chr&gt;              &lt;chr&gt;    \n 1 id                 character\n 2 date               POSIXct  \n 3 land               logical  \n 4 lon                numeric  \n 5 lat                numeric  \n 6 daysFromDeployment numeric  \n 7 haulout            logical  \n 8 dist2col           numeric  \n 9 tripdur            difftime \n10 trip               numeric  \n11 is_trip_complete   logical  \n12 SUS                logical  \n\nSample size: 14162 records\n\n\nCode\nfemale_info &lt;- get_dataset_info(files$female_data_path, \"female_data\")\n\n\n\n=== Dataset: female_data ===\n\nTime Coverage:\n# A tibble: 1 × 3\n  start_date          end_date            n_records\n  &lt;dttm&gt;              &lt;dttm&gt;                  &lt;int&gt;\n1 2000-02-03 00:00:00 2010-10-24 19:31:03    101905\n\nSpatial Coverage:\n# A tibble: 1 × 4\n  lon_min lon_max lat_min lat_max\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    110.    241.   -76.5   -43.1\n\nNumber of unique IDs: 67 \n\nVariables and their classes:\n# A tibble: 7 × 2\n  variable class    \n  &lt;chr&gt;    &lt;chr&gt;    \n1 id       factor   \n2 date     POSIXct  \n3 lon      numeric  \n4 lat      numeric  \n5 type     character\n6 month    numeric  \n7 season   character\n\nSample size: 101905 records\n\n\nCode\nparticle_info &lt;- get_dataset_info(files$particle_data_path, \"particle_data\")\n\n\n\n=== Dataset: particle_data ===\n\nTime Coverage:\n# A tibble: 1 × 3\n  start_date          end_date            n_records\n  &lt;dttm&gt;              &lt;dttm&gt;                  &lt;int&gt;\n1 1995-11-29 00:00:00 2001-10-03 00:00:00      5603\n\nSpatial Coverage:\n# A tibble: 1 × 4\n  lon_min lon_max lat_min lat_max\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    158.    173.   -61.4   -52.3\n\nNumber of unique IDs: 48 \n\nVariables and their classes:\n# A tibble: 6 × 2\n  variable       class    \n  &lt;chr&gt;          &lt;chr&gt;    \n1 lon            numeric  \n2 lat            numeric  \n3 group          integer  \n4 date           POSIXct  \n5 id             character\n6 date_processed Date     \n\nSample size: 5603 records\n\n\nCode\nsurface_particle_info &lt;- get_dataset_info(files$surface_particle_data_path, \"surface_particle_data\")\n\n\n\n=== Dataset: surface_particle_data ===\n\nTime Coverage:\n# A tibble: 1 × 3\n  start_date          end_date            n_records\n  &lt;dttm&gt;              &lt;dttm&gt;                  &lt;int&gt;\n1 1995-11-29 11:00:00 2001-10-03 10:00:00     11164\n\nSpatial Coverage:\n# A tibble: 1 × 4\n  lon_min lon_max lat_min lat_max\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1   -180.    180.   -65.3   -47.3\n\nNumber of unique IDs: 48 \n\nVariables and their classes:\n# A tibble: 7 × 2\n  variable class    \n  &lt;chr&gt;    &lt;chr&gt;    \n1 x        numeric  \n2 y        numeric  \n3 group    integer  \n4 lon      numeric  \n5 lat      numeric  \n6 date     POSIXct  \n7 id       character\n\nSample size: 11164 records\n\n\n\n\nCode\n# Export CSVs\nseal_info$data %&gt;%\n    ungroup() %&gt;%\n    st_drop_geometry() %&gt;%\n    rename(flag = SUS) %&gt;%\n    select(id, date, lon, lat, flag) %&gt;%\n    write_csv(paste0(tools::file_path_sans_ext(files$seal_data_path), \".csv\"))\n\nfemale_info$data %&gt;%\n    select(id, date, lon, lat, type, month, season) %&gt;%\n    write_csv(paste0(tools::file_path_sans_ext(files$female_data_path), \".csv\"))\n\nparticle_info$data %&gt;%\n    select(id, date, lon, lat) %&gt;%\n    write_csv(paste0(tools::file_path_sans_ext(files$particle_data_path), \".csv\"))\n\nsurface_particle_info$data %&gt;%\n    select(id, date, lon, lat) %&gt;%\n    write_csv(paste0(tools::file_path_sans_ext(files$surface_particle_data_path), \".csv\"))\n\n\n\n\nCode\n# Combine all metadata into a list\nall_metadata &lt;- list(\n    seal_data = seal_info,\n    female_data = female_info,\n    particle_data = particle_info,\n    surface_particle_data = surface_particle_info\n)\n\n# Save metadata as RDS for potential future use\nwrite_rds(all_metadata, here(\"output\", \"dataset_metadata.rds\"))\n\n# Create a simplified metadata summary as CSV\nmetadata_summary &lt;- bind_rows(\n    seal_info$time_range %&gt;% mutate(dataset = \"seal_data\"),\n    female_info$time_range %&gt;% mutate(dataset = \"female_data\"),\n    particle_info$time_range %&gt;% mutate(dataset = \"particle_data\"),\n    surface_particle_info$time_range %&gt;% mutate(dataset = \"surface_particle_data\")\n) %&gt;%\n    select(dataset, everything())\n\nwrite_csv(metadata_summary, here(\"output\", \"dataset_metadata_summary.csv\"))\n#"
  },
  {
    "objectID": "code/dispersal-analysis.html",
    "href": "code/dispersal-analysis.html",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(circular)\nlibrary(sf)\nlibrary(move)\nlibrary(conflicted)\nlibrary(patchwork)\nlibrary(skimr)\nlibrary(gtsummary)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(summarytools)\nlibrary(GGally)\nlibrary(broom)\nlibrary(DHARMa)\nlibrary(MuMIn)\nlibrary(here)\n\nconflicts_prefer(dplyr::filter, dplyr::select, dplyr::mutate, dplyr::group_by)\n\ntheme_set(theme_bw())\n\n# Define output folder\noutput_folder &lt;- here(\"output\", \"dispersal_analysis_3\")\n\n# Create the output folder if it doesn't exist\ndir.create(output_folder, showWarnings = FALSE, recursive = TRUE)"
  },
  {
    "objectID": "code/dispersal-analysis.html#data-loading-and-preprocessing",
    "href": "code/dispersal-analysis.html#data-loading-and-preprocessing",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Data Loading and Preprocessing",
    "text": "Data Loading and Preprocessing\n\n\nCode\nseal_data_path &lt;- here(\"output\", \"tracks_processed_12h.rds\")\nfemale_data_path &lt;- here(\"data\", \"adult_female_locs.rds\")\nparticle_data_path &lt;- here(\"output\", \"particle-trace-186.13m.rds\")\nsurface_particle_data_path &lt;- here(\"output\", \"currently_particleTrace.rds\")\n\nsource(here(\"code\", \"functions\", \"functions.R\"))\n\ncolony &lt;- cbind(158.95, -54.5)\n\n# Include your function definitions\n\ncalculate_distance_from_start &lt;- function(data, colony = cbind(158.95, -54.5)) {\n    data %&gt;%\n        group_by(id) %&gt;%\n        mutate(\n            distance_from_start = geosphere::distGeo(\n                cbind(colony[1], colony[2]),\n                cbind(lon, lat)\n            )\n        )\n}\n\nidentify_outbound_trip &lt;- function(data) {\n    data %&gt;%\n        calculate_distance_from_start() %&gt;%\n        group_by(id) %&gt;%\n        arrange(id, date) %&gt;%\n        mutate(\n            max_distance = max(distance_from_start),\n            is_outbound = distance_from_start &lt;= max_distance & row_number() &lt;= which.max(distance_from_start)\n        ) %&gt;%\n        ungroup()\n}\n\nnormalize_longitude &lt;- function(lon) {\n    ((lon + 180) %% 360) - 180\n}\n\ninterpolate_track &lt;- function(data) {\n    data &lt;- data %&gt;% as.data.frame()\n\n    # Print the number of rows before processing\n    cat(\"Total rows before processing:\", nrow(data), \"\\n\")\n\n    processed_data &lt;- data %&gt;%\n        group_split(id) %&gt;%\n        map_dfr(~ {\n            id &lt;- .$id %&gt;% unique()\n            cat(\"Processing \", id, \"...\\n\")\n            initial_rows &lt;- nrow(.)\n            do_interpolate &lt;- FALSE\n\n            # Create move object\n            move_obj &lt;- move(\n                x = .$lon,\n                y = .$lat,\n                time = .$date,\n                proj = CRS(\"+proj=longlat +datum=WGS84\"),\n                data = .,\n            )\n\n            # Only interpolate if there are gaps larger than 1 day\n            time_diffs &lt;- difftime(.$date, lag(.$date), units = \"days\") %&gt;% as.numeric()\n            if (all(time_diffs %&gt;% na.omit() != 1)) {\n                cat(\"time interval not 1 day. interpolating...\\n\")\n                do_interpolate &lt;- TRUE\n                interpolated &lt;- interpolateTime(move_obj, time = as.difftime(24, units = \"hours\"), spaceMethod = \"greatcircle\")\n            } else {\n                interpolated &lt;- move_obj\n            }\n\n            result &lt;- interpolated %&gt;%\n                as_tibble() %&gt;%\n                mutate(id = id, date = as.Date(date)) %&gt;%\n                dplyr::select(-lon, -lat) %&gt;%\n                rename(lon = coords.x1, lat = coords.x2) %&gt;%\n                dplyr::select(id, date, lon, lat, everything())\n\n            if (do_interpolate) {\n                cat(\"interpolated from\", initial_rows, \"to\", nrow(result), \"rows\\n\")\n            }\n            return(result)\n        })\n\n    return(processed_data)\n}\n\npreprocess_track &lt;- function(data) {\n    data %&gt;%\n        mutate(lon = normalize_longitude(lon)) %&gt;%\n        # drop_na(lon, lat) %&gt;%\n        arrange(id, date) %&gt;%\n        group_by(id) %&gt;%\n        interpolate_track() %&gt;%\n        calculate_bearings() %&gt;%\n        mutate(bearing = make_circular(bearing)) %&gt;%\n        identify_outbound_trip()\n}\n\n# Calculate days since start for each id\ncalculate_days_since_start &lt;- function(data) {\n    data %&gt;%\n        group_by(id) %&gt;%\n        arrange(id, date) %&gt;%\n        mutate(days_since_start = as.numeric(difftime(date, first(date), units = \"days\"))) %&gt;%\n        ungroup()\n}\n\n\n\n\nCode\nlocw &lt;- readRDS(seal_data_path) %&gt;%\n    filter(trip == 1, SUS == FALSE) %&gt;%\n    dplyr::select(-daysFromDeployment, -SUS, -trip, -dist2col, -haulout) %&gt;%\n    preprocess_track() %&gt;%\n    convert2polarsf(remove_coords = FALSE) %&gt;%\n    filter(is_outbound)\n\nlocf &lt;- readRDS(female_data_path) %&gt;%\n    preprocess_track() %&gt;%\n    convert2polarsf(remove_coords = FALSE) %&gt;%\n    filter(is_outbound)\n\nlocp &lt;- readRDS(particle_data_path) %&gt;%\n    preprocess_track() %&gt;%\n    convert2polarsf(remove_coords = FALSE)\n\nlocps &lt;- readRDS(surface_particle_data_path) %&gt;%\n    preprocess_track() %&gt;%\n    convert2polarsf(remove_coords = FALSE)"
  },
  {
    "objectID": "code/dispersal-analysis.html#data-summary",
    "href": "code/dispersal-analysis.html#data-summary",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Data Summary",
    "text": "Data Summary\n\n\nNumber of unique ids in locf: 67 \n\n\nNumber of unique ids in locw: 48 \n\n\nNumber of unique ids in locps: 48 \n\n\nNumber of unique ids in locp: 48"
  },
  {
    "objectID": "code/dispersal-analysis.html#plotting-all-tracks",
    "href": "code/dispersal-analysis.html#plotting-all-tracks",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Plotting All Tracks",
    "text": "Plotting All Tracks\n\n\nCode\n# Option 1: Colorblind-friendly palette with muted tones\npalette1 &lt;- c(\n    \"Female\" = \"#999999\", # Muted grey\n    \"Weaner\" = \"#E69F00\", # Orange\n    \"Particle 0m\" = \"#56B4E9\", # Light blue\n    \"Particle 186m\" = \"#0072B2\" # Dark blue\n)\n\n# Option 2: Palette with richer colors\npalette2 &lt;- c(\n    \"Female\" = \"#7F7F7F\", # Warm grey\n    \"Weaner\" = \"#D55E00\", # Rich orange-red\n    \"Particle 0m\" = \"#69B3E7\", # Sky blue\n    \"Particle 186m\" = \"#1B4B8C\" # Deep navy\n)\n\n# Option 3: Palette with more contrast\npalette3 &lt;- c(\n    \"Female\" = \"#8C8C8C\", # Medium grey\n    \"Weaner\" = \"#CC3311\", # Bright red\n    \"Particle 0m\" = \"#33B2FF\", # Bright blue\n    \"Particle 186m\" = \"#004C99\" # Dark blue\n)\n\n\n# Get the bounding box of all tracks combined\nbb &lt;- sf::st_bbox(\n    sf::st_union(\n        sf::st_union(locf),\n        sf::st_union(locw),\n        sf::st_union(locps),\n        sf::st_union(locp)\n    )\n)\n\n# Add nudge values for the labels\norsi_sf &lt;- orsi_sf %&gt;%\n    mutate(\n        nudge_x = c(-1000, -4800, -4500, -4000),\n        nudge_y = c(0, 5300, 4800, 3000),\n        front = toupper(front)\n    )\n\n# Convert Macquarie Island coordinates to sf object\nmq_sf &lt;- st_as_sf(data.frame(lon = 158.95, lat = -54.5),\n    coords = c(\"lon\", \"lat\"),\n    crs = 4326\n) # assuming WGS84\n\n\nall_tracks_plot &lt;- ggplot() +\n    geom_sf(data = orsi_sf, linetype = \"dashed\", colour = \"grey30\") +\n    geom_sf_text(\n        data = orsi_sf,\n        aes(label = front),\n        nudge_x = orsi_sf$nudge_x,\n        nudge_y = orsi_sf$nudge_y\n    ) +\n    geom_sf(data = locf, aes(color = \"Female\"), alpha = 0.4, size = .5) +\n    geom_sf(data = locw, aes(color = \"Weaner\"), alpha = 0.4, size = .5) +\n    geom_sf(data = locps, aes(color = \"Particle 0m\"), alpha = 0.4, size = .5) +\n    geom_sf(data = locp, aes(color = \"Particle 186m\"), alpha = 0.4, size = .5) +\n    geom_sf(data = mq_sf, shape = 17, size = 3, color = \"black\") +\n    theme_bw() +\n    # Set the x and y limits using the bounding box\n    coord_sf(\n        xlim = c(bb[\"xmin\"], bb[\"xmax\"]),\n        ylim = c(bb[\"ymin\"], bb[\"ymax\"] + 1000)\n    ) +\n    scale_color_manual(values = palette3) +\n    labs(color = \"Group\", x = \"Longitude\", y = \"Latitude\")\n\nall_tracks_plot\n\n\n\n\n\nAll tracks plot with ORSI fronts\n\n\n\n\nCode\nggsave(file.path(output_folder, \"all_tracks_plot.png\"), all_tracks_plot, width = 8, height = 4)"
  },
  {
    "objectID": "code/dispersal-analysis.html#bearing-analysis",
    "href": "code/dispersal-analysis.html#bearing-analysis",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Bearing Analysis",
    "text": "Bearing Analysis\n\n\nCode\n## Create circular plot of all bearings for each data set\nplot_bearing_histogram &lt;- function(data, title = NULL) {\n    # Calculate mean bearing\n    mean_bearing &lt;- mean.circular(data$bearing, na.rm = TRUE)\n    # mean_bearing &lt;- data$bearing %&gt;% median.circular(na.rm = TRUE)\n\n    p &lt;- data %&gt;%\n        ggplot(aes(x = bearing)) +\n        geom_histogram(binwidth = 10, boundary = 0) +\n        coord_polar(start = 0, direction = 1) +\n        scale_x_continuous(\n            breaks = seq(0, 360, by = 45),\n            limits = c(0, 360),\n            labels = c(\"N\", \"\", \"E\", \"\", \"S\", \"\", \"W\", \"\", \"N\")\n        ) +\n        theme_bw() +\n        labs(x = NULL, y = \"Count\") +\n        theme(\n            axis.text.y = element_blank(),\n            axis.ticks.y = element_blank()\n        ) +\n        # Add arrow for mean bearing\n        annotate(\"segment\",\n            x = mean_bearing, y = 0, xend = mean_bearing, yend = Inf,\n            arrow = arrow(length = unit(0.5, \"cm\")), color = \"red\", linewidth = 1\n        ) +\n        # Add text label for mean bearing\n        annotate(\"text\",\n            x = mean_bearing, y = Inf, label = sprintf(\"%.1f°\", as.numeric(mean_bearing)),\n            color = \"red\", vjust = 1.1, hjust = -0.1\n        )\n\n    if (!is.null(title)) {\n        p &lt;- p + labs(title = title)\n    } else {\n        p &lt;- p + theme(plot.title = element_blank())\n    }\n\n    return(p)\n}\n\n# All sequential outbound bearings\np_list &lt;- list(locw, locps, locf, locp)\np_names &lt;- c(\"Weaner\", \"Particle 0m\", \"Female\", \"Particle 186m\")\n\n# Map of all bearings for each data set\nall_bearings_plot &lt;- map2(p_list, p_names, plot_bearing_histogram) %&gt;%\n    wrap_plots(ncol = 2)\n\nall_bearings_plot\n\n\n\n\n\nAll sequential outbound bearings\n\n\n\n\nCode\nggsave(file.path(output_folder, \"all_bearings_plot.png\"), all_bearings_plot, width = 12, height = 10)"
  },
  {
    "objectID": "code/dispersal-analysis.html#create-mean-bearings-by-id",
    "href": "code/dispersal-analysis.html#create-mean-bearings-by-id",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Create mean bearings by id",
    "text": "Create mean bearings by id\n\n\nCode\n# Calculate mean bearings by id\nprocess_by_id &lt;- function(data) {\n    data %&gt;%\n        group_by(id) %&gt;%\n        summarize(mean_bearing = mean.circular(bearing, na.rm = TRUE), sd_bearing = sd.circular(bearing, na.rm = TRUE)) %&gt;%\n        rename(bearing = mean_bearing)\n}\n\n\nlocw_by_id &lt;- locw %&gt;% process_by_id()\nlocps_by_id &lt;- locps %&gt;% process_by_id()\nlocf_by_id &lt;- locf %&gt;% process_by_id()\nlocp_by_id &lt;- locp %&gt;% process_by_id()\n\np_list &lt;- list(locw_by_id, locps_by_id, locf_by_id, locp_by_id)\np_names &lt;- c(\"Weaner\", \"Particle 0m\", \"Female\", \"Particle 186m\")\n\n# Map of mean bearings by id\nmean_bearings_plot &lt;- map2(p_list, p_names, plot_bearing_histogram) %&gt;%\n    wrap_plots(ncol = 2, guides = \"collect\")\n\nmean_bearings_plot\n\n\n\n\n\nMean bearings by id\n\n\n\n\nCode\nggsave(file.path(output_folder, \"mean_bearings_plot.png\"), mean_bearings_plot, width = 12, height = 10)"
  },
  {
    "objectID": "code/dispersal-analysis.html#comparing-bearings",
    "href": "code/dispersal-analysis.html#comparing-bearings",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Comparing Bearings",
    "text": "Comparing Bearings\n\n\nCode\ncompare_bearings &lt;- function(data1, data2, group1_name, group2_name, bearing_varname) {\n    data1 &lt;- data1 %&gt;% rename(bearing = !!bearing_varname)\n    data2 &lt;- data2 %&gt;% rename(bearing = !!bearing_varname)\n\n    # Calculate mean bearings\n    mean_bearing_1 &lt;- mean.circular(data1$bearing, na.rm = TRUE)\n    mean_bearing_2 &lt;- mean.circular(data2$bearing, na.rm = TRUE)\n\n    # Perform Watson-Williams test\n    watson_test &lt;- watson.two.test(data1$bearing, data2$bearing)\n\n    # Create tidy table for results\n    results_table &lt;- tibble(\n        Group = c(group1_name, group2_name),\n        Mean_Bearing = c(as.numeric(mean_bearing_1), as.numeric(mean_bearing_2)),\n        SD_Bearing = c(sd.circular(data1$bearing, na.rm = TRUE), sd.circular(data2$bearing, na.rm = TRUE))\n    )\n\n    # Print results\n    print(results_table)\n    print(watson_test)\n\n    cb_palette &lt;- c(\"#D55E00\", \"#0072B2\")\n\n    ggplot() +\n        geom_histogram(data = data1, aes(x = bearing, fill = group1_name), alpha = 1, binwidth = 10, boundary = 0) +\n        geom_histogram(data = data2, aes(x = bearing, fill = group2_name), alpha = 0.6, binwidth = 10, boundary = 0) +\n        coord_polar(start = 0, direction = 1) +\n        scale_x_continuous(\n            breaks = seq(0, 360, by = 45),\n            limits = c(0, 360),\n            labels = c(\"N\", \"\", \"E\", \"\", \"S\", \"\", \"W\", \"\", \"N\")\n        ) +\n        scale_fill_manual(values = setNames(cb_palette, c(group1_name, group2_name))) +\n        labs(x = NULL, y = \"Count\", fill = \"Bearings\") +\n        theme(\n            panel.grid.major = element_line(color = \"gray90\"),\n            panel.grid.minor = element_blank(),\n            legend.position = \"bottom\"\n        ) +\n        annotate(\"segment\",\n            x = mean_bearing_1, y = 0, xend = mean_bearing_1, yend = Inf,\n            arrow = arrow(length = unit(0.5, \"cm\")), color = cb_palette[1], linewidth = 1\n        ) +\n        annotate(\"segment\",\n            x = mean_bearing_2, y = 0, xend = mean_bearing_2, yend = Inf,\n            arrow = arrow(length = unit(0.5, \"cm\")), color = cb_palette[2], linewidth = 1\n        ) +\n        annotate(\"text\",\n            x = mean_bearing_1, y = Inf,\n            label = sprintf(\"%.1f°\", as.numeric(mean_bearing_1)),\n            color = cb_palette[1], vjust = 1.1, hjust = -0.1, size = 3\n        ) +\n        annotate(\"text\",\n            x = mean_bearing_2, y = Inf,\n            label = sprintf(\"%.1f°\", as.numeric(mean_bearing_2)),\n            color = cb_palette[2], vjust = 1.1, hjust = -0.1, size = 3\n        )\n}\n\n## Compare individual mean bearings\np1 &lt;- compare_bearings(locw_by_id, locf_by_id, \"Pups\", \"Adult Females\", \"bearing\")\n\n\n# A tibble: 2 × 3\n  Group         Mean_Bearing SD_Bearing\n  &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;\n1 Pups                  120.      0.969\n2 Adult Females         138.      1.23 \n\n      Watson's Two-Sample Test of Homogeneity \n\nTest Statistic: 0.221 \n0.01 &lt; P-value &lt; 0.05 \n \n\n\nCode\np1\n\n\n\n\n\nCode\np2 &lt;- compare_bearings(locw_by_id, locps_by_id, \"Pups\", \"Particle 0m\", \"bearing\")\n\n\n# A tibble: 2 × 3\n  Group       Mean_Bearing SD_Bearing\n  &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;\n1 Pups                120.      0.969\n2 Particle 0m         115.      0.629\n\n      Watson's Two-Sample Test of Homogeneity \n\nTest Statistic: 0.1768 \n0.05 &lt; P-value &lt; 0.10 \n \n\n\nCode\np2\n\n\n\n\n\nCode\np3 &lt;- compare_bearings(locw_by_id, locp_by_id, \"Pups\", \"Particle 186m\", \"bearing\")\n\n\n# A tibble: 2 × 3\n  Group         Mean_Bearing SD_Bearing\n  &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;\n1 Pups                 120.       0.969\n2 Particle 186m         92.8      0.471\n\n      Watson's Two-Sample Test of Homogeneity \n\nTest Statistic: 0.4125 \nP-value &lt; 0.001 \n \n\n\nCode\np3"
  },
  {
    "objectID": "code/dispersal-analysis.html#categorise-seals-as-following-current-if-they-are-within-45-deg-of-the-mean-trace-direction",
    "href": "code/dispersal-analysis.html#categorise-seals-as-following-current-if-they-are-within-45-deg-of-the-mean-trace-direction",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Categorise seals as following current if they are within 45 deg of the mean trace direction",
    "text": "Categorise seals as following current if they are within 45 deg of the mean trace direction\n\n\nCode\n### Categorise seals as following current if they are within 45 deg of the mean trace direction\nlocw_by_id &lt;- locw_by_id %&gt;%\n    left_join(locps_by_id %&gt;% st_drop_geometry() %&gt;% select(id, bearing, sd_bearing), by = \"id\", suffix = c(\"_seal\", \"_pt0m\")) %&gt;%\n    mutate(\n        angle_diff_seal_pt0m = angle_diff(bearing_seal, bearing_pt0m),\n        is_following_0m = angle_diff_seal_pt0m &lt; 45\n    )\n\n# Add 186m particle data\nlocw_by_id &lt;- locw_by_id %&gt;%\n    left_join(locp_by_id %&gt;% st_drop_geometry() %&gt;% select(id, bearing, sd_bearing) %&gt;% rename(bearing_pt186m = bearing, sd_bearing_pt186m = sd_bearing), by = \"id\") %&gt;%\n    mutate(\n        angle_diff_seal_pt186m = angle_diff(bearing_seal, bearing_pt186m),\n        is_following_186m = angle_diff_seal_pt186m &lt; 45\n    )\n\nlocw_by_id %&gt;%\n    st_drop_geometry() %&gt;%\n    left_join(get_survival_data(), by = \"id\") %&gt;%\n    select(id, is_following_0m, is_following_186m, survive_trip_1, survive_year_1) %&gt;%\n    pivot_longer(\n        cols = c(is_following_0m, is_following_186m),\n        names_to = \"particle_depth\",\n        values_to = \"is_following\"\n    ) %&gt;%\n    mutate(particle_depth = if_else(particle_depth == \"is_following_0m\", \"0m\", \"186m\")) %&gt;%\n    group_by(particle_depth, is_following) %&gt;%\n    summarise(\n        n = n(),\n        prop = (n / nrow(locw_by_id)) %&gt;% round(2),\n        n_survived_trip_1 = sum(survive_trip_1, na.rm = TRUE),\n        prop_survived_trip_1 = (n_survived_trip_1 / n()) %&gt;% round(2),\n        n_survived_year_1 = sum(survive_year_1, na.rm = TRUE),\n        prop_survived_year_1 = (n_survived_year_1 / n()) %&gt;% round(2),\n        .groups = \"drop\"\n    ) %&gt;%\n    mutate(is_following = if_else(is_following, \"Following\", \"Not following\")) %&gt;%\n    gt(groupname_col = \"particle_depth\") %&gt;%\n    fmt_percent(columns = c(prop, prop_survived_trip_1, prop_survived_year_1), decimals = 0) %&gt;%\n    cols_label(\n        is_following = \"Following Particle\",\n        n = \"Count\",\n        prop = \"Proportion\",\n        n_survived_trip_1 = \"Survived Trip 1\",\n        prop_survived_trip_1 = \"% Survived Trip 1\",\n        n_survived_year_1 = \"Survived Year 1\",\n        prop_survived_year_1 = \"% Survived Year 1\"\n    ) %&gt;%\n    tab_style(\n        style = cell_text(weight = \"bold\"),\n        locations = cells_row_groups()\n    ) %&gt;%\n    cols_merge(\n        columns = c(n, prop),\n        pattern = \"{1} ({2})\"\n    ) %&gt;%\n    cols_merge(\n        columns = c(n_survived_trip_1, prop_survived_trip_1),\n        pattern = \"{1} ({2})\"\n    ) %&gt;%\n    cols_merge(\n        columns = c(n_survived_year_1, prop_survived_year_1),\n        pattern = \"{1} ({2})\"\n    ) %&gt;%\n    cols_label(\n        n = \"Count (%)\",\n        n_survived_trip_1 = \"Survived Trip 1 (%)\",\n        n_survived_year_1 = \"Survived Year 1 (%)\"\n    ) %&gt;%\n    gtsave(file.path(output_folder, \"following_particle_survival.docx\"))"
  },
  {
    "objectID": "code/dispersal-analysis.html#calculate-cumulative-mean-bearings",
    "href": "code/dispersal-analysis.html#calculate-cumulative-mean-bearings",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Calculate cumulative mean bearings",
    "text": "Calculate cumulative mean bearings\n\n\nCode\n# Calculate cumulative mean bearings\ncalculate_circular_cummean &lt;- function(bearings) {\n    n &lt;- length(bearings)\n\n    sapply(1:n, function(i) {\n        bearings_subset &lt;- bearings[1:i]\n        mean_bearing &lt;- mean.circular(bearings_subset)\n    })\n}\n\n# Combine weaner and particle data\nw_pt &lt;- locw %&gt;%\n    left_join(locps %&gt;% st_drop_geometry() %&gt;% select(id, date, bearing), by = c(\"id\", \"date\"), suffix = c(\"_seal\", \"_pt\")) %&gt;%\n    left_join(locp %&gt;% st_drop_geometry() %&gt;% select(id, date, bearing) %&gt;% rename(bearing_pt186m = bearing), by = c(\"id\", \"date\")) %&gt;%\n    group_by(id) %&gt;%\n    mutate(\n        cummean_bearing_seal = calculate_circular_cummean(bearing_seal),\n        cummean_bearing_pt = calculate_circular_cummean(bearing_pt),\n        cummean_bearing_pt186m = calculate_circular_cummean(bearing_pt186m),\n        days_since_start = as.numeric(date - first(date)),\n        angle_diff_seal_pt = angle_diff(cummean_bearing_seal, cummean_bearing_pt),\n        angle_diff_seal_pt186m = angle_diff(cummean_bearing_seal, cummean_bearing_pt186m),\n    ) %&gt;%\n    left_join(locw_by_id %&gt;% st_drop_geometry() %&gt;% select(id, is_following_0m, is_following_186m), by = \"id\")"
  },
  {
    "objectID": "code/dispersal-analysis.html#explore-difference-in-cumulative-bearings-between-seal-and-particle-over-time",
    "href": "code/dispersal-analysis.html#explore-difference-in-cumulative-bearings-between-seal-and-particle-over-time",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Explore difference in cumulative bearings between seal and particle over time",
    "text": "Explore difference in cumulative bearings between seal and particle over time\n\n\nCode\n# Plot angle difference over time\np1 &lt;- w_pt %&gt;%\n    ggplot(aes(x = days_since_start, y = id)) +\n    geom_tile(aes(fill = angle_diff_seal_pt)) +\n    scale_fill_viridis_c(option = \"B\") +\n    theme_bw() +\n    facet_wrap(~is_following_0m, scales = \"free\", labeller = as_labeller(c(`TRUE` = \"following\", `FALSE` = \"not following\"))) +\n    labs(x = \"Days since start\", y = \"Seal ID\", fill = \"Δ Bearing - 0 m (°)\") +\n    theme(legend.position = \"bottom\", text = element_text(size = 8))\n\np1\n\n\n\n\n\nCode\np2 &lt;- w_pt %&gt;%\n    ggplot(aes(x = days_since_start, y = id)) +\n    geom_tile(aes(fill = angle_diff_seal_pt186m)) +\n    facet_wrap(~is_following_186m, scales = \"free\", labeller = as_labeller(c(`TRUE` = \"following\", `FALSE` = \"not following\"))) +\n    scale_fill_viridis_c(option = \"B\") +\n    labs(x = \"Days since start\", y = \"Seal ID\", fill = \"Δ Bearing - 200 m (°)\") +\n    theme(legend.position = \"bottom\", text = element_text(size = 8))\n\np2"
  },
  {
    "objectID": "code/dispersal-analysis.html#plot-angle-difference-tracks",
    "href": "code/dispersal-analysis.html#plot-angle-difference-tracks",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Plot angle difference tracks",
    "text": "Plot angle difference tracks\n\n\nCode\n## Plot angle difference tracks\n\nplots1 &lt;- w_pt %&gt;%\n    rename(x1 = cummean_bearing_seal, x2 = cummean_bearing_pt, y = days_since_start) %&gt;%\n    select(id, is_following_0m, x1, x2, y) %&gt;%\n    group_split(id) %&gt;%\n    map(~ ggplot(data = .x) +\n        geom_point(aes(x = x1, y = y, color = \"Pups\"), size = 0.2, alpha = .5) +\n        geom_point(aes(x = x2, y = y, color = \"Particle\"), size = 0.2, alpha = .5) +\n        coord_polar() +\n        scale_x_continuous(limits = c(0, 360)) +\n        scale_color_manual(values = c(\"Pups\" = \"#D55E00\", \"Particle\" = \"gray20\")) +\n        theme_bw() +\n        theme(\n            legend.position = \"bottom\", text = element_text(size = 8),\n            panel.border = element_rect(color = ifelse(.x$is_following_0m[1], \"#0072B2\", \"grey70\"), linewidth = 1)\n        ) +\n        labs(x = NULL, y = \"Days since start\", color = \"Group\", subtitle = .x$id[1]))\n\no &lt;- order(w_pt %&gt;% group_by(id, is_following_0m) %&gt;% nest() %&gt;% pull(is_following_0m))\n\nplots1 &lt;- plots1[o]\n\np1 &lt;- wrap_plots(plots1, guides = \"collect\") +\n    plot_annotation(title = \"0 m\") &\n    theme(legend.position = \"bottom\", axis.title = element_blank())\n\np1\n\n\n\n\n\nAngle difference tracks\n\n\n\n\nCode\nggsave(file.path(output_folder, \"angle_diff_tracks_0m.png\"), p1, width = 10, height = 10, dpi = 300, bg = \"white\")\n\n\nplots2 &lt;- w_pt %&gt;%\n    rename(x1 = cummean_bearing_seal, x2 = cummean_bearing_pt186m, y = days_since_start) %&gt;%\n    select(id, is_following_186m, x1, x2, y) %&gt;%\n    group_split(id) %&gt;%\n    map(~ ggplot(data = .x) +\n        geom_point(aes(x = x1, y = y, color = \"Pups\"), size = 0.2, alpha = .5) +\n        geom_point(aes(x = x2, y = y, color = \"Particle\"), size = 0.2, alpha = .5) +\n        coord_polar() +\n        scale_x_continuous(limits = c(0, 360)) +\n        scale_color_manual(values = c(\"Pups\" = \"#D55E00\", \"Particle\" = \"gray20\")) +\n        theme_bw() +\n        theme(\n            legend.position = \"bottom\", text = element_text(size = 8),\n            panel.border = element_rect(color = ifelse(.x$is_following_186m[1], \"#0072B2\", \"grey70\"), linewidth = 1)\n        ) +\n        labs(x = NULL, y = \"Days since start\", color = \"Group\", subtitle = .x$id[1]))\n\no &lt;- order(w_pt %&gt;% group_by(id, is_following_186m) %&gt;% nest() %&gt;% pull(is_following_186m))\n\nplots2 &lt;- plots2[o]\n\np2 &lt;- wrap_plots(plots2, guides = \"collect\") +\n    plot_annotation(title = \"200 m\") &\n    theme(legend.position = \"bottom\", axis.title = element_blank())\n\np2\n\n\n\n\n\nAngle difference tracks\n\n\n\n\nCode\nggsave(file.path(output_folder, \"angle_diff_tracks_186m.png\"), p2, width = 10, height = 10, dpi = 300, bg = \"white\")"
  },
  {
    "objectID": "code/dispersal-analysis.html#fit-first-trip-survival-model",
    "href": "code/dispersal-analysis.html#fit-first-trip-survival-model",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Fit first trip survival model",
    "text": "Fit first trip survival model\n\n\nCode\nmodel_data &lt;- model_data_all %&gt;%\n    drop_na(weanmass) %&gt;%\n    mutate(across(where(is.numeric), ~ scale(.)))\n\nmodel_trip &lt;- glm(survive_trip_1 ~ is_following_0m + is_following_186m + weanmass + birthyear + sst + ssha + eke + slope + SSTgrad + ice + chlgrad,\n    data = model_data, family = binomial(link = \"logit\"), na.action = \"na.fail\"\n)\n\nmodel &lt;- model_trip\n\nevaluate_model(model_trip)\n\n\n\n\n--- Summary of model_trip (global model) ---\n\nglm(formula = survive_trip_1 ~ is_following_0m + is_following_186m + \n    weanmass + birthyear + sst + ssha + eke + slope + SSTgrad + \n    ice + chlgrad, family = binomial(link = \"logit\"), data = model_data, \n    na.action = \"na.fail\")\n# A tibble: 12 × 5\n   term                  estimate std.error statistic p.value\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)             0.313      0.934    0.335   0.737 \n 2 is_following_0mTRUE     0.704      1.09     0.647   0.518 \n 3 is_following_186mTRUE   0.168      1.04     0.161   0.872 \n 4 weanmass                0.0228     0.476    0.0479  0.962 \n 5 birthyear               0.467      0.577    0.810   0.418 \n 6 sst                     0.931      0.832    1.12    0.263 \n 7 ssha                    1.32       0.849    1.56    0.120 \n 8 eke                     0.693      0.992    0.699   0.485 \n 9 slope                   0.588      0.528    1.11    0.265 \n10 SSTgrad                -1.12       0.660   -1.70    0.0884\n11 ice                    -0.110      0.433   -0.253   0.800 \n12 chlgrad                 0.182      0.393    0.463   0.644 \n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1          58.6      44  -23.1  70.1  91.8     46.1          33    45\n\n\n--- DHARMa model checking for trip survival model ---\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated\n\ndata:  simulationOutput\ndispersion = 1.0257, p-value = 0.892\nalternative hypothesis: two.sided\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = 1.0057, p-value = 1\nalternative hypothesis: two.sided\n\n\n\n\n\n\n    DHARMa bootstrapped outlier test\n\ndata:  dharma\noutliers at both margin(s) = 0, observations = 45, p-value = 1\nalternative hypothesis: two.sided\n percent confidence interval:\n 0 0\nsample estimates:\noutlier frequency (expected: 0 ) \n                               0 \n\n\nFixed term is \"(Intercept)\"\n\n\n\n\n--- Dredge (model selection) summary ---\n\n   model_name                                                     formula     AICc      BIC deviance df.residual null.deviance df.null delta_AICc\n1          17                        survive_trip_1 ~ is_following_0m + 1 58.27032 61.59793 53.98460          43      58.57363      44  0.0000000\n2          65                                  survive_trip_1 ~ slope + 1 59.20669 62.53430 54.92098          43      58.57363      44  0.9363759\n3          81                survive_trip_1 ~ is_following_0m + slope + 1 59.66646 64.50109 53.08110          42      58.57363      44  1.3961479\n4         145                 survive_trip_1 ~ is_following_0m + ssha + 1 59.73652 64.57114 53.15116          42      58.57363      44  1.4662045\n5          33                      survive_trip_1 ~ is_following_186m + 1 59.80832 63.13593 55.52261          43      58.57363      44  1.5380068\n6         533        survive_trip_1 ~ eke + is_following_0m + SSTgrad + 1 59.88602 66.11267 50.88602          41      58.57363      44  1.6157009\n7         529              survive_trip_1 ~ is_following_0m + SSTgrad + 1 59.90034 64.73497 53.31498          42      58.57363      44  1.6300270\n8          21                  survive_trip_1 ~ eke + is_following_0m + 1 59.95555 64.79018 53.37019          42      58.57363      44  1.6852376\n9         577                        survive_trip_1 ~ slope + SSTgrad + 1 60.02630 64.86092 53.44093          42      58.57363      44  1.7559792\n10        193                           survive_trip_1 ~ slope + ssha + 1 60.08203 64.91665 53.49666          42      58.57363      44  1.8117116\n11        273                  survive_trip_1 ~ is_following_0m + sst + 1 60.09842 64.93304 53.51305          42      58.57363      44  1.8280988\n12         49    survive_trip_1 ~ is_following_0m + is_following_186m + 1 60.09844 64.93306 53.51307          42      58.57363      44  1.8281220\n13        661 survive_trip_1 ~ eke + is_following_0m + ssha + SSTgrad + 1 60.10013 67.59498 48.56167          40      58.57363      44  1.8298135\n\n\n--- Model averaging summary ---\n\n\nCall:\nmodel.avg(object = best_models)\n\nComponent model call: \nglm(formula = survive_trip_1 ~ &lt;13 unique rhs&gt;, family = binomial(link = \"logit\"), data = model_data, na.action = na.fail)\n\nComponent models: \n     df logLik  AICc delta weight\n2     2 -26.99 58.27  0.00   0.16\n4     2 -27.46 59.21  0.94   0.10\n24    3 -26.54 59.67  1.40   0.08\n25    3 -26.58 59.74  1.47   0.07\n3     2 -27.76 59.81  1.54   0.07\n127   4 -25.44 59.89  1.62   0.07\n27    3 -26.66 59.90  1.63   0.07\n12    3 -26.69 59.96  1.69   0.07\n47    3 -26.72 60.03  1.76   0.06\n45    3 -26.75 60.08  1.81   0.06\n26    3 -26.76 60.10  1.83   0.06\n23    3 -26.76 60.10  1.83   0.06\n1257  5 -24.28 60.10  1.83   0.06\n\nTerm codes: \n              eke   is_following_0m is_following_186m             slope              ssha               sst           SSTgrad \n                1                 2                 3                 4                 5                 6                 7 \n\nModel-averaged coefficients:  \n(full average) \n                      Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)\n(Intercept)           -0.02991    0.62232     0.63392   0.047    0.962\nis_following_0mTRUE    0.95279    0.86611     0.87816   1.085    0.278\nslope                  0.17749    0.34363     0.34714   0.511    0.609\nssha                   0.09413    0.27919     0.28320   0.332    0.740\nis_following_186mTRUE  0.11723    0.41371     0.41879   0.280    0.780\neke                    0.14139    0.41796     0.42316   0.334    0.738\nSSTgrad               -0.15009    0.35643     0.36046   0.416    0.677\nsst                    0.01465    0.10313     0.10527   0.139    0.889\n \n(conditional average) \n                      Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)  \n(Intercept)           -0.02991    0.62232     0.63392   0.047   0.9624  \nis_following_0mTRUE    1.35713    0.72093     0.74140   1.830   0.0672 .\nslope                  0.58527    0.38821     0.39839   1.469   0.1418  \nssha                   0.46941    0.46102     0.47306   0.992   0.3211  \nis_following_186mTRUE  0.86920    0.78447     0.80423   1.081   0.2798  \neke                    0.70958    0.68816     0.70391   1.008   0.3134  \nSSTgrad               -0.56427    0.49387     0.50476   1.118   0.2636  \nsst                    0.23415    0.34442     0.35464   0.660   0.5091  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n--- Variable importance ---\n\n                     is_following_0m SSTgrad slope ssha is_following_186m eke  sst  ice  chlgrad birthyear weanmass\nSum of weights:      0.49            0.44    0.42  0.40 0.33              0.31 0.28 0.24 0.23    0.23      0.22    \nN containing models: 1024            1024    1024  1024 1024              1024 1024 1024 1024    1024      1024"
  },
  {
    "objectID": "code/dispersal-analysis.html#fit-first-year-survival-model",
    "href": "code/dispersal-analysis.html#fit-first-year-survival-model",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Fit first year survival model",
    "text": "Fit first year survival model\n\n\nCode\n## Year survival\nmodel_year &lt;- glm(survive_year_1 ~ is_following_0m + is_following_186m + weanmass + birthyear + sst + ssha + eke + slope + SSTgrad + ice + chlgrad,\n    data = model_data, family = binomial(link = \"logit\"), na.action = \"na.fail\"\n)\n\nevaluate_model(model_year)\n\n\n\n\n--- Summary of model_trip (global model) ---\n\nglm(formula = survive_year_1 ~ is_following_0m + is_following_186m + \n    weanmass + birthyear + sst + ssha + eke + slope + SSTgrad + \n    ice + chlgrad, family = binomial(link = \"logit\"), data = model_data, \n    na.action = \"na.fail\")\n# A tibble: 12 × 5\n   term                  estimate std.error statistic p.value\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)            -1.81       1.15    -1.58    0.114 \n 2 is_following_0mTRUE     1.62       1.28     1.27    0.205 \n 3 is_following_186mTRUE   0.0464     1.28     0.0364  0.971 \n 4 weanmass                1.14       0.499    2.29    0.0219\n 5 birthyear              -0.374      0.552   -0.677   0.498 \n 6 sst                     0.279      0.756    0.369   0.712 \n 7 ssha                    0.717      0.521    1.38    0.169 \n 8 eke                     0.364      0.704    0.517   0.605 \n 9 slope                   0.325      0.489    0.665   0.506 \n10 SSTgrad                -0.0907     0.536   -0.169   0.866 \n11 ice                    -0.114      0.557   -0.204   0.838 \n12 chlgrad                -0.727      0.789   -0.921   0.357 \n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1          59.7      44  -22.5  68.9  90.6     44.9          33    45\n\n\n--- DHARMa model checking for trip survival model ---\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs. simulated\n\ndata:  simulationOutput\ndispersion = 1.031, p-value = 0.85\nalternative hypothesis: two.sided\n\n\n\n\n\n\n    DHARMa zero-inflation test via comparison to expected zeros with simulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = 0.99312, p-value = 1\nalternative hypothesis: two.sided\n\n\n\n\n\n\n    DHARMa bootstrapped outlier test\n\ndata:  dharma\noutliers at both margin(s) = 0, observations = 45, p-value = 1\nalternative hypothesis: two.sided\n percent confidence interval:\n 0 0\nsample estimates:\noutlier frequency (expected: 0 ) \n                               0 \n\n\nFixed term is \"(Intercept)\"\n\n\n\n\n--- Dredge (model selection) summary ---\n\n   model_name                                                                       formula     AICc      BIC deviance df.residual null.deviance df.null delta_AICc\n1        1217                                  survive_year_1 ~ slope + ssha + weanmass + 1 59.30001 65.52666 50.30001          41      59.66692      44 0.00000000\n2        1425                  survive_year_1 ~ is_following_0m + ssha + sst + weanmass + 1 59.32833 66.82318 47.78987          40      59.66692      44 0.02831627\n3        1173                  survive_year_1 ~ eke + is_following_0m + ssha + weanmass + 1 59.47861 66.97346 47.94014          40      59.66692      44 0.17859472\n4        1169                        survive_year_1 ~ is_following_0m + ssha + weanmass + 1 59.70655 65.93320 50.70655          41      59.66692      44 0.40654175\n5        1047          survive_year_1 ~ chlgrad + eke + is_following_0m + weanmass +      1 59.83252 67.32737 48.29406          40      59.66692      44 0.53251014\n6        1473                            survive_year_1 ~ slope + ssha + sst + weanmass + 1 59.99098 67.48584 48.45252          40      59.66692      44 0.69097360\n7        1045                         survive_year_1 ~ eke + is_following_0m + weanmass + 1 60.24620 66.47285 51.24620          41      59.66692      44 0.94618574\n8        1043                     survive_year_1 ~ chlgrad + is_following_0m + weanmass + 1 60.29998 66.52663 51.29998          41      59.66692      44 0.99997170\n9        1153                                          survive_year_1 ~ ssha + weanmass + 1 60.31085 65.14548 53.72549          42      59.66692      44 1.01084363\n10       1041                               survive_year_1 ~ is_following_0m + weanmass + 1 60.59700 65.43162 54.01164          42      59.66692      44 1.29699211\n11       1299          survive_year_1 ~ chlgrad + is_following_0m + sst + weanmass +      1 60.66698 68.16183 49.12852          40      59.66692      44 1.36696714\n12       1427   survive_year_1 ~ chlgrad + is_following_0m + ssha + sst + weanmass +      1 60.68489 69.31434 46.47437          39      59.66692      44 1.38488277\n13       1218                      survive_year_1 ~ birthyear + slope + ssha + weanmass + 1 60.69941 68.19426 49.16095          40      59.66692      44 1.39939574\n14       1175   survive_year_1 ~ chlgrad + eke + is_following_0m + ssha + weanmass +      1 60.73187 69.36132 46.52134          39      59.66692      44 1.43186001\n15       1089                                         survive_year_1 ~ slope + weanmass + 1 60.76038 65.59500 54.17501          42      59.66692      44 1.46036529\n16       1221                            survive_year_1 ~ eke + slope + ssha + weanmass + 1 60.76448 68.25934 49.22602          40      59.66692      44 1.46447312\n17       1219                        survive_year_1 ~ chlgrad + slope + ssha + weanmass + 1 60.86178 68.35663 49.32332          40      59.66692      44 1.56176762\n18       1171         survive_year_1 ~ chlgrad + is_following_0m + ssha + weanmass +      1 60.87568 68.37053 49.33721          40      59.66692      44 1.57566526\n19        193                                             survive_year_1 ~ slope + ssha + 1 60.89231 65.72694 54.30695          42      59.66692      44 1.59230372\n20       1170       survive_year_1 ~ birthyear + is_following_0m + ssha + weanmass +      1 60.91938 68.41423 49.38092          40      59.66692      44 1.61936829\n21       1489     survive_year_1 ~ is_following_0m + slope + ssha + sst + weanmass +      1 60.95446 69.58391 46.74394          39      59.66692      44 1.65445241\n22       1091                               survive_year_1 ~ chlgrad + slope + weanmass + 1 60.96738 67.19403 51.96738          41      59.66692      44 1.66736874\n23       1157                                    survive_year_1 ~ eke + ssha + weanmass + 1 60.97137 67.19802 51.97137          41      59.66692      44 1.67136193\n24       1233           survive_year_1 ~ is_following_0m + slope + ssha + weanmass +      1 60.98930 68.48415 49.45084          40      59.66692      44 1.68929191\n25       1025                                                 survive_year_1 ~ weanmass + 1 61.22367 64.55128 56.93796          43      59.66692      44 1.92365836\n26       1174 survive_year_1 ~ birthyear + eke + is_following_0m + ssha + weanmass +      1 61.28456 69.91401 47.07403          39      59.66692      44 1.98454661\n\n\n--- Model averaging summary ---\n\n\nCall:\nmodel.avg(object = best_models)\n\nComponent model call: \nglm(formula = survive_year_1 ~ &lt;26 unique rhs&gt;, family = binomial(link = \"logit\"), data = model_data, na.action = na.fail)\n\nComponent models: \n      df logLik  AICc delta weight\n568    4 -25.15 59.30  0.00   0.07\n4678   5 -23.89 59.33  0.03   0.07\n3468   5 -23.97 59.48  0.18   0.06\n468    4 -25.35 59.71  0.41   0.06\n2348   5 -24.15 59.83  0.53   0.05\n5678   5 -24.23 59.99  0.69   0.05\n348    4 -25.62 60.25  0.95   0.04\n248    4 -25.65 60.30  1.00   0.04\n68     3 -26.86 60.31  1.01   0.04\n48     3 -27.01 60.60  1.30   0.04\n2478   5 -24.56 60.67  1.37   0.03\n24678  6 -23.24 60.68  1.38   0.03\n1568   5 -24.58 60.70  1.40   0.03\n23468  6 -23.26 60.73  1.43   0.03\n58     3 -27.09 60.76  1.46   0.03\n3568   5 -24.61 60.76  1.46   0.03\n2568   5 -24.66 60.86  1.56   0.03\n2468   5 -24.67 60.88  1.58   0.03\n56     3 -27.15 60.89  1.59   0.03\n1468   5 -24.69 60.92  1.62   0.03\n45678  6 -23.37 60.95  1.65   0.03\n258    4 -25.98 60.97  1.67   0.03\n368    4 -25.99 60.97  1.67   0.03\n4568   5 -24.73 60.99  1.69   0.03\n8      2 -28.47 61.22  1.92   0.03\n13468  6 -23.54 61.28  1.98   0.03\n\nTerm codes: \n      birthyear         chlgrad             eke is_following_0m           slope            ssha             sst        weanmass \n              1               2               3               4               5               6               7               8 \n\nModel-averaged coefficients:  \n(full average) \n                    Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)  \n(Intercept)         -1.22976    0.82217     0.83601   1.471   0.1413  \nslope                0.22988    0.39109     0.39567   0.581   0.5612  \nssha                 0.50887    0.50065     0.50901   1.000   0.3174  \nweanmass             0.78189    0.42738     0.43754   1.787   0.0739 .\nis_following_0mTRUE  0.95217    1.05545     1.06887   0.891   0.3730  \nsst                  0.14218    0.34562     0.34963   0.407   0.6843  \neke                  0.15434    0.32251     0.32637   0.473   0.6363  \nchlgrad             -0.21778    0.49360     0.50131   0.434   0.6640  \nbirthyear           -0.04073    0.18777     0.19083   0.213   0.8310  \n \n(conditional average) \n                    Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)  \n(Intercept)          -1.2298     0.8222      0.8360   1.471   0.1413  \nslope                 0.6325     0.4076      0.4196   1.507   0.1317  \nssha                  0.7188     0.4507      0.4638   1.550   0.1211  \nweanmass              0.8065     0.4106      0.4215   1.913   0.0557 .\nis_following_0mTRUE   1.5890     0.9204      0.9459   1.680   0.0930 .\nsst                   0.6708     0.4572      0.4713   1.423   0.1547  \neke                   0.5600     0.3876      0.3991   1.403   0.1606  \nchlgrad              -0.7647     0.6613      0.6813   1.122   0.2617  \nbirthyear            -0.4592     0.4531      0.4673   0.983   0.3258  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n--- Variable importance ---\n\n                     weanmass ssha is_following_0m slope chlgrad eke  sst  birthyear is_following_186m ice  SSTgrad\nSum of weights:      0.73     0.55 0.49            0.39  0.38    0.33 0.30 0.25      0.25              0.24 0.23   \nN containing models: 1024     1024 1024            1024  1024    1024 1024 1024      1024              1024 1024"
  },
  {
    "objectID": "code/dispersal-analysis.html#create-summary-table-for-all-pups",
    "href": "code/dispersal-analysis.html#create-summary-table-for-all-pups",
    "title": "Southern Elephant Seal Pup Dispersal Analysis",
    "section": "Create summary table for all pups",
    "text": "Create summary table for all pups"
  },
  {
    "objectID": "code/functions.html",
    "href": "code/functions.html",
    "title": "Utility Functions",
    "section": "",
    "text": "Code\nrequire(tidyverse)\nrequire(lubridate)\nrequire(conflicted)\nrequire(here)\n\n\nconflicts_prefer(dplyr::summarise, dplyr::filter, dplyr::lag, purrr::map, dplyr::select, .quiet = TRUE)\n\nsource(here(\"code\", \"functions\", \"bearing_utils.R\"))\nsource(here(\"code\", \"functions\", \"convert2polarsf.R\"))\nsource(here(\"code\", \"functions\", \"preprocess_seal_particle_data.R\"))\nsource(here(\"code\", \"functions\", \"print_and_save_results.R\"))\nsource(here(\"code\", \"functions\", \"unwrap_lon.R\"))\nload(here(\"baseInfo.Rdata\"))\n\n\n# Custom Functions ---------------------------------------------------------\ncalcMeanDepartureDate &lt;- function(dates, type = \"median\") {\n  dates_formatted &lt;- purrr::map(dates, function(x) {\n    ifelse(!month(x) %in% c(11, 12), format(x, \"2000-%m-%d\"), format(x, \"1999-%m-%d\"))\n  }) %&gt;%\n    unlist() %&gt;%\n    as.Date()\n\n  if (type == \"median\") {\n    return(dates_formatted %&gt;% median())\n  }\n  if (type == \"mean\") {\n    return(dates_formatted %&gt;% mean())\n  }\n  if (type == \"sd\") {\n    return(dates_formatted %&gt;% sd())\n  }\n}\n\nsaveDepartureDateResult &lt;- function(results_table, dates, age_group) {\n  return(\n    bind_rows(\n      results_table,\n      tibble(\n        age_group = age_group,\n        n = dates %&gt;% length(),\n        median = calcMeanDepartureDate(dates = dates),\n        mean = calcMeanDepartureDate(dates, \"mean\"),\n        sd = calcMeanDepartureDate(dates, \"sd\"),\n        median_yday = calcMeanDepartureDate(dates) %&gt;% yday()\n      )\n    )\n  )\n}\n\n# survival\n# create function to determine survival\nget_survival_data &lt;- function() {\n  require(tidyverse)\n  all_data_weaners &lt;- readRDS(here(\"output\", \"all_data_combined.rds\"))\n  all_data_weaners %&gt;%\n    filter(sim == 0, trip == 1) %&gt;%\n    group_by(id) %&gt;%\n    summarise(\n      seen_6m = if (any(seen_6m == TRUE)) TRUE else FALSE,\n      seen_1y = if (any(seen_1y == TRUE)) TRUE else FALSE,\n      is_trip_complete = if (all(is_trip_complete == TRUE)) TRUE else FALSE,\n      weanmass = first(weanmass),\n      birthyear = first(birthyear),\n      survive_trip_1 = ifelse(is_trip_complete == TRUE | seen_6m == TRUE, TRUE, FALSE),\n      survive_year_1 = ifelse(seen_1y == TRUE, TRUE, FALSE),\n    ) %&gt;%\n    mutate(\n      size = case_when(\n        weanmass &gt; 135 ~ \"heavy\",\n        weanmass &lt; 96 ~ \"light\",\n        TRUE ~ \"avg\"\n      ),\n      weanmass = ifelse(is.na(weanmass), NA, weanmass)\n    )\n}\n\nload_all_data_weaners &lt;- function() {\n  all_data_weaners &lt;- readRDS(here(\"output\", \"all_data_combined.rds\"))\n  return(all_data_weaners)\n}"
  },
  {
    "objectID": "code/functions.html#r-functions",
    "href": "code/functions.html#r-functions",
    "title": "Utility Functions",
    "section": "",
    "text": "Code\nrequire(tidyverse)\nrequire(lubridate)\nrequire(conflicted)\nrequire(here)\n\n\nconflicts_prefer(dplyr::summarise, dplyr::filter, dplyr::lag, purrr::map, dplyr::select, .quiet = TRUE)\n\nsource(here(\"code\", \"functions\", \"bearing_utils.R\"))\nsource(here(\"code\", \"functions\", \"convert2polarsf.R\"))\nsource(here(\"code\", \"functions\", \"preprocess_seal_particle_data.R\"))\nsource(here(\"code\", \"functions\", \"print_and_save_results.R\"))\nsource(here(\"code\", \"functions\", \"unwrap_lon.R\"))\nload(here(\"baseInfo.Rdata\"))\n\n\n# Custom Functions ---------------------------------------------------------\ncalcMeanDepartureDate &lt;- function(dates, type = \"median\") {\n  dates_formatted &lt;- purrr::map(dates, function(x) {\n    ifelse(!month(x) %in% c(11, 12), format(x, \"2000-%m-%d\"), format(x, \"1999-%m-%d\"))\n  }) %&gt;%\n    unlist() %&gt;%\n    as.Date()\n\n  if (type == \"median\") {\n    return(dates_formatted %&gt;% median())\n  }\n  if (type == \"mean\") {\n    return(dates_formatted %&gt;% mean())\n  }\n  if (type == \"sd\") {\n    return(dates_formatted %&gt;% sd())\n  }\n}\n\nsaveDepartureDateResult &lt;- function(results_table, dates, age_group) {\n  return(\n    bind_rows(\n      results_table,\n      tibble(\n        age_group = age_group,\n        n = dates %&gt;% length(),\n        median = calcMeanDepartureDate(dates = dates),\n        mean = calcMeanDepartureDate(dates, \"mean\"),\n        sd = calcMeanDepartureDate(dates, \"sd\"),\n        median_yday = calcMeanDepartureDate(dates) %&gt;% yday()\n      )\n    )\n  )\n}\n\n# survival\n# create function to determine survival\nget_survival_data &lt;- function() {\n  require(tidyverse)\n  all_data_weaners &lt;- readRDS(here(\"output\", \"all_data_combined.rds\"))\n  all_data_weaners %&gt;%\n    filter(sim == 0, trip == 1) %&gt;%\n    group_by(id) %&gt;%\n    summarise(\n      seen_6m = if (any(seen_6m == TRUE)) TRUE else FALSE,\n      seen_1y = if (any(seen_1y == TRUE)) TRUE else FALSE,\n      is_trip_complete = if (all(is_trip_complete == TRUE)) TRUE else FALSE,\n      weanmass = first(weanmass),\n      birthyear = first(birthyear),\n      survive_trip_1 = ifelse(is_trip_complete == TRUE | seen_6m == TRUE, TRUE, FALSE),\n      survive_year_1 = ifelse(seen_1y == TRUE, TRUE, FALSE),\n    ) %&gt;%\n    mutate(\n      size = case_when(\n        weanmass &gt; 135 ~ \"heavy\",\n        weanmass &lt; 96 ~ \"light\",\n        TRUE ~ \"avg\"\n      ),\n      weanmass = ifelse(is.na(weanmass), NA, weanmass)\n    )\n}\n\nload_all_data_weaners &lt;- function() {\n  all_data_weaners &lt;- readRDS(here(\"output\", \"all_data_combined.rds\"))\n  return(all_data_weaners)\n}"
  }
]